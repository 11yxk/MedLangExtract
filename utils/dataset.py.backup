import json
import os
import torch
import pandas as pd
import random
import re
from monai.transforms import ( Compose, Lambdad, NormalizeIntensityd,RandCoarseShuffled,RandRotated,RandZoomd,
                              Resized, ToTensord, LoadImaged, EnsureChannelFirstd)
from torch.utils.data import DataLoader, Dataset
from transformers import AutoTokenizer

class QaTa(Dataset):

    def __init__(self, json_path=None, root_path=None, tokenizer=None, mode='train', image_size=[224,224], 
                 progressive_level='P5', mask_prob=0.05):
        """
        初始化数据集
        Args:
            json_path: JSON文件路径
            root_path: 图像根目录路径
            tokenizer: 分词器路径
            mode: 模式 ('train', 'valid', 'test')
            image_size: 图像尺寸
            progressive_level: progressive text级别 ('P0'-'P5')
            mask_prob: P5级别时属性值masking概率
        """
        super(QaTa, self).__init__()

        self.mode = mode
        self.progressive_level = progressive_level
        self.mask_prob = mask_prob
        
        # 读取JSON数据
        with open(json_path, 'r', encoding='utf-8') as f:
            self.data = json.load(f)
        
        # 提取图像和文本信息
        self.image_list = [item['img_name'] for item in self.data]
        self.mask_list = [item['mask_name'] for item in self.data]
        self.text_data = self.data  # 保存完整的文本数据

        # 根据模式分割数据（如果需要的话，这里假设JSON文件已经按模式分好了）
        # 如果需要按比例分割，可以取消注释以下代码
        # if mode == 'train':
        #     data_len = len(self.data)
        #     self.data = self.data[:int(0.8*data_len)]
        #     self.image_list = self.image_list[:int(0.8*len(self.image_list))]
        #     self.mask_list = self.mask_list[:int(0.8*len(self.mask_list))]
        # elif mode == 'valid':
        #     data_len = len(self.data)
        #     self.data = self.data[int(0.8*data_len):]
        #     self.image_list = self.image_list[int(0.8*len(self.image_list)):]
        #     self.mask_list = self.mask_list[int(0.8*len(self.mask_list)):]

        self.root_path = root_path
        self.image_size = image_size

        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer, trust_remote_code=True)

    def __len__(self):
        return len(self.image_list)
    
    def apply_attribute_masking(self, text):
        """
        对P5级别的文本应用属性masking
        每个属性独立地以mask_prob概率被替换为None
        """
        if self.progressive_level != 'P5':
            return text
        
        # 定义可能被mask的属性
        maskable_attributes = ['region_entity', 'location', 'color', 'shape', 'size']
        
        masked_text = text
        
        # 对每个属性独立判断是否mask
        for attr in maskable_attributes:
            if random.random() < self.mask_prob:  # 每个属性独立地应用概率
                # 使用正则表达式找到并替换属性值
                pattern = rf'{attr}:\s*[^,\]]+' 
                replacement = f'{attr}: None'
                masked_text = re.sub(pattern, replacement, masked_text)
        
        return masked_text

    def __getitem__(self, idx):
        trans = self.transform(self.image_size)

        # 获取图像和mask路径
        image = os.path.join(self.root_path, 'images', self.image_list[idx])
        gt = os.path.join(self.root_path, 'masks', self.mask_list[idx])
        
        # 根据progressive_level获取文本
        text_item = self.text_data[idx]
        caption = text_item[self.progressive_level]['text']
        
        # 如果是P5级别，应用masking
        if self.progressive_level == 'P5':
            caption = self.apply_attribute_masking(caption)

        # 处理文本tokenization
        token_output = self.tokenizer.encode_plus(
            caption, 
            padding='max_length',
            max_length=64,  # 增加最大长度以适应更长的描述
            truncation=True,
            return_attention_mask=True,
            return_tensors='pt'
        )
        token, mask = token_output['input_ids'], token_output['attention_mask']

        data = {'image': image, 'gt': gt, 'token': token, 'mask': mask}
        data = trans(data)

        image, gt, token, mask = data['image'], data['gt'], data['token'], data['mask']
        gt = torch.where(gt == 255, 1, 0)
        
        # Ensure GT is single channel (take first channel if multi-channel)
        if gt.shape[0] == 3:
            gt = gt[0:1]  # Take only the first channel
            
        text = {'input_ids': token.squeeze(dim=0), 'attention_mask': mask.squeeze(dim=0)} 

        return ([image, text], gt)

    def transform(self,image_size=[224,224]):

        if self.mode == 'train':  # for training mode
            trans = Compose([
                LoadImaged(["image","gt"], reader='PILReader'),
                EnsureChannelFirstd(["image","gt"]),
                RandZoomd(['image','gt'],min_zoom=0.95,max_zoom=1.2,mode=["bicubic","nearest"],prob=0.1),
                Resized(["image"],spatial_size=image_size,mode='bicubic'),
                Resized(["gt"],spatial_size=image_size,mode='nearest'),
                NormalizeIntensityd(['image'], channel_wise=True),
                ToTensord(["image","gt","token","mask"]),
            ])
        
        else:  # for valid and test mode: remove random zoom
            trans = Compose([
                LoadImaged(["image","gt"], reader='PILReader'),
                EnsureChannelFirstd(["image","gt"]),
                Resized(["image"],spatial_size=image_size,mode='bicubic'),
                Resized(["gt"],spatial_size=image_size,mode='nearest'),
                NormalizeIntensityd(['image'], channel_wise=True),
                ToTensord(["image","gt","token","mask"]),

            ])

        return trans


def main():
    """
    测试数据集的各种功能
    """
    print("=== 测试修改后的QaTa数据集类 ===\n")
    
    # 配置参数
    json_path = './data/text_annotations/kvasir_text/kvasir_polyp_progressive_test.json'
    root_path = './data/Kvasir-SEG'
    tokenizer_path = './lib/BiomedVLP-CXR-BERT-specialized'
    
    print("1. 测试不同Progressive Level:")
    print("-" * 50)
    
    # 测试不同的progressive level
    for level in ['P0', 'P1', 'P2', 'P3', 'P4', 'P5']:
        try:
            # 创建数据集实例
            dataset = QaTa(
                json_path=json_path,
                root_path=root_path,
                tokenizer=tokenizer_path,
                mode='test',
                progressive_level=level,
                mask_prob=0.0  # 先不使用masking
            )
            
            print(f"Level {level}:")
            print(f"  数据集大小: {len(dataset)}")
            
            # 获取第一个样本的文本
            original_text = dataset.text_data[0][level]['text']
            print(f"  示例文本: '{original_text}'")
            print(f"  文本长度: {len(original_text)}")
            print()
            
        except Exception as e:
            print(f"Level {level} 错误: {e}\n")
    
    print("2. 测试P5级别的Masking功能:")
    print("-" * 50)
    
    try:
        # 获取原始P5文本
        with open(json_path, 'r', encoding='utf-8') as f:
            test_data = json.load(f)
        original_p5_text = test_data[0]['P5']['text']
        print(f"原始P5文本: {original_p5_text}")
        
        # 测试不同的mask概率
        for prob in [0.2, 0.5, 1.0]:
            print(f"\n--- mask_prob = {prob} 的示例 ---")
            dataset_p5 = QaTa(
                json_path=json_path,
                root_path=root_path,
                tokenizer=tokenizer_path,
                mode='test',
                progressive_level='P5',
                mask_prob=prob
            )
            
            # 生成3个masking示例
            for i in range(3):
                masked_text = dataset_p5.apply_attribute_masking(original_p5_text)
                print(f"  示例{i+1}: {masked_text}")
        
    except Exception as e:
        print(f"P5 Masking测试错误: {e}")
    
    print("\n3. 测试数据加载功能:")
    print("-" * 50)
    
    try:
        # 创建一个简单的数据集进行加载测试
        dataset_simple = QaTa(
            json_path=json_path,
            root_path=root_path,
            tokenizer=tokenizer_path,
            mode='test',
            progressive_level='P3',
            mask_prob=0.1
        )
        
        print(f"数据集创建成功，大小: {len(dataset_simple)}")
        
        # 尝试获取第一个样本（这会测试完整的数据加载流程）
        print("尝试加载第一个样本...")
        sample = dataset_simple[0]
        images, gt = sample
        image, text = images
        
        print(f"✓ 图像tensor形状: {image.shape}")
        print(f"✓ GT tensor形状: {gt.shape}")
        print(f"✓ 文本token形状: {text['input_ids'].shape}")
        print(f"✓ 注意力mask形状: {text['attention_mask'].shape}")
        print("✓ 数据加载成功！")
        
    except Exception as e:
        print(f"数据加载测试错误: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n=== 测试完成 ===")


if __name__ == "__main__":
    main()
